{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、导入需要用到的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm #progress bar 进度条\n",
    "import tensorflow as tf\n",
    "if tf.__version__ != '1.0.0':\n",
    "    print(\"please check the version of tensorflow!\")\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display #用来显示图片\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、tqdm用法示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "for i in tqdm(range(10)):  \n",
    "     sleep(1)\n",
    "     pass  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、准备相关工具"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、全连接层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _dense(x, scope, out_dim, activation = True):\n",
    "    '''\n",
    "    _dense用于构建生成器和判别器\n",
    "    x：是一个2-D的array或者tensor\n",
    "    scope：用来区分不同层的参数\n",
    "    out_dim：int类型，输出的每个sample的维度数\n",
    "    activation：是否需要添加激活函数relu\n",
    "    '''\n",
    "    in_dim = int(x.shape[-1])\n",
    "    #输入x可能是tenor，也可能是array，能同时取得tensor和array的shape用x.shape\n",
    "    #如果是tensor输出的类型是tensor_shape.Dimension，如果是array的话输出的类型是int\n",
    "    #所以tensor_shape.Dimension要转换成int，这对本身就是int类型的不造成影响\n",
    "    \n",
    "    with tf.variable_scope(scope): \n",
    "        w = tf.get_variable('w', [in_dim, out_dim], initializer=tf.random_normal_initializer(stddev=0.01))\n",
    "        #w的shape为[in_dim, out_dim]，对应的矩阵乘法应该是tf.matmul(x, w)\n",
    "        b = tf.get_variable('b', [out_dim], initializer=tf.constant_initializer(0))\n",
    "    \n",
    "    if activation:\n",
    "        output = tf.nn.relu(tf.matmul(x, w) + b)\n",
    "    else:\n",
    "        output = tf.matmul(x, w) + b\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取tensor的shape有三种方式:tensor.shape,tensor.get_shape().as_list(),tf.shape()\n",
    "\n",
    "获取array的shape:array.shape\n",
    "\n",
    "注意适用对象和返回值的类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    \"\"\"rescale x\n",
    "    \"\"\"\n",
    "    return x*2-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、将一个batch的100张图片汇总在一张大图片中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_vis(imgs):\n",
    "    \"\"\"imgs是一个list\n",
    "    list的每一个元素是一个28*28的图片\n",
    "    这个函数的作用是将一个batch的手写数字汇总在一个图片里面,供展示所用\"\"\"\n",
    "    \n",
    "    nh = nw = int(np.ceil(np.sqrt(len(imgs))))\n",
    "    h, w = imgs[0].shape\n",
    "    grid = np.zeros((nh*h, nw*w))\n",
    "    for n, img in enumerate(imgs):\n",
    "        i, j = n%nh, n//nh\n",
    "        grid[j*h:(j+1)*h, i*w:(i+1)*w] = img\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4、图片可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(grid):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    plt.title('G: %.3f D: %.3f Updates: %d'%(loss_g_, loss_d_, n_updates))\n",
    "    plt.imshow(grid, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    display.clear_output(wait=True)#清除旧的\n",
    "    display.display(plt.gcf())#展示新的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、定义生成器和判别器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, reuse = None):\n",
    "    '''shape of z is [batch_size, 100]'''\n",
    "    with tf.variable_scope('generator', reuse = reuse):\n",
    "        hidden_layer_1 = _dense(z, 'l_1', 512)\n",
    "        hidden_layer_2 = _dense(hidden_layer_1, 'l_2', 1024)\n",
    "        output = _dense(hidden_layer_2, 'output', 784)\n",
    "        return output\n",
    "\n",
    "def discriminator(x, reuse = None):\n",
    "    '''x is a 2-D tensor'''\n",
    "    with tf.variable_scope('discriminator', reuse = reuse):\n",
    "        hidden_layer_1 = _dense(x, 'l_1', 512)\n",
    "        hidden_layer_2 = _dense(hidden_layer_1, 'l_2', 1024)\n",
    "        logits = _dense(hidden_layer_2, 'logits', 1, activation = False)\n",
    "        output = tf.sigmoid(logits)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四、准备数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、真实数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets('.\\MNIST_data', one_hot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、噪声数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_z(batch_size):\n",
    "    return np.random.rand(batch_size, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据测试\n",
    "_get_z(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype = tf.float32, shape = [None, 784])\n",
    "y = tf.placeholder(dtype = tf.int32, shape = [None, 10])\n",
    "z = tf.placeholder(dtype = tf.float32, shape = [None, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 五、建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = generator(z)#g展示为图片需要做preprocess的你操作\n",
    "d_g = discriminator(g)\n",
    "d_real = discriminator(preprocess(x), reuse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为什么d_real的reuse = True？见下面的原理图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 六、定义损失函数及优化器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_d = -tf.reduce_sum(tf.log(d_real) + tf.log(1-d_g))\n",
    "#loss_g = tf.reduce_sum(tf.log(d_real) + tf.log(1-d_g))\n",
    "#loss_g = tf.reduce_sum(tf.log(d_real) - tf.log(d_g))\n",
    "loss_g = tf.reduce_sum(-tf.log(d_g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\min _{G}\\max _{ D } V(D,G)={ E }_{ x ～ { p }_  { data } (x) }[logD(x)] + { E }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))]\\ $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./G的loss改进.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在最开始的时候，生成器生成的对象很容易被判别器判别出来，也就是说判别器判别出来的概率和实际情况非常相符，那么交叉熵就接近于0，误差反向传播传递的梯度就很小，生成器的参数更新就很慢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2.5e-4\n",
    "\n",
    "g_vars  = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='generator')\n",
    "g_train = tf.train.AdamOptimizer(learning_rate=lr, beta1=0.5).minimize(loss_g,  var_list=g_vars)\n",
    "\n",
    "d_vars  = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='discriminator')\n",
    "d_train = tf.train.AdamOptimizer(learning_rate=lr, beta1=0.5).minimize(loss_d,  var_list=d_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练g的时候d保持不动，训练d的时候g保持不动"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![原理](./GAN.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 七、训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init & sess\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "k = 10 #每训练k次g，只训练一次d\n",
    "for n_updates in tqdm(range(5000)):\n",
    "    \n",
    "    x_, _ = mnist.train.next_batch(100)\n",
    "    \n",
    "    imgs = (sess.run(g, {z:_get_z(100)}) + 1)/2.0\n",
    "    imgs = imgs.reshape([-1, 28, 28])\n",
    "    grid = grid_vis(imgs)\n",
    "    \n",
    "    sess.run(g_train, {z:_get_z(100), x:x_})\n",
    "    if n_updates%k == 0:\n",
    "        sess.run(d_train, {z:_get_z(100), x:x_})\n",
    "    \n",
    "    if n_updates%10 == 0:\n",
    "        loss_g_ = sess.run(loss_g, {z:_get_z(100), x:x_})\n",
    "        loss_d_ = sess.run(loss_d, {z:_get_z(100), x:x_})\n",
    "        visualize(grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
